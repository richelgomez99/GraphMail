# ========================================
# GRAPHMAIL Configuration
# ========================================
#
# This file documents all available configuration options.
# Copy this file to .env and set your values.
#
# Priority: Environment Variables > .env File > Defaults
#
# Constitutional Alignment:
# - Article VII: API-First Design (environment-specific deployments)
# - Article VIII: Security by Default (secrets management)
# ========================================

# ========================================
# Environment Configuration
# ========================================

# Deployment environment: development, staging, or production
# Default: development
ENVIRONMENT=development

# ========================================
# Logging Configuration
# ========================================

# Log verbosity level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Recommendations:
#   - development: DEBUG (verbose logging for debugging)
#   - staging: INFO (moderate logging)
#   - production: WARNING (minimal logging for performance)
# Default: INFO
LOG_LEVEL=INFO

# ========================================
# API Keys (REQUIRED)
# ========================================

# OpenAI API key for GPT models (e.g., gpt-4o)
# At least one API key (OpenAI or Anthropic) is REQUIRED
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API key for Claude models (e.g., claude-3-5-sonnet-20241022)
# Optional if OpenAI key is provided
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ========================================
# Email Processing Configuration
# ========================================

# Maximum email body length in characters
# Range: 1000-10000
# Default: 5000
EMAIL_BODY_MAX_LENGTH=5000

# ========================================
# Retry Configuration
# ========================================

# Maximum retry attempts for LLM API calls (Range: 0-10, Default: 3)
MAX_RETRIES=3

# Base delay for exponential backoff in seconds (Range: 0.1-10.0, Default: 1.0)
RETRY_BASE_DELAY=1.0

# Maximum total retry time in seconds (Range: 1.0-60.0, Default: 10.0)
RETRY_MAX_TOTAL_TIME=10.0

# ========================================
# Rate Limiting Configuration
# ========================================

# Maximum LLM API calls per minute (Range: 1-1000, Default: 50)
RATE_LIMIT_PER_MINUTE=50

# Enable rate limiting for LLM API calls (Default: true)
ENABLE_RATE_LIMITING=true

# ========================================
# Model Configuration
# ========================================

# Model name for Agent 2 (Extractor) - Default: gpt-4o
AGENT2_MODEL=gpt-4o

# Model name for Agent 3 (Verifier) - Default: claude-3-5-sonnet-20241022
AGENT3_MODEL=claude-3-5-sonnet-20241022

# ========================================
# File System Configuration
# ========================================

# Directory for output files - Default: ./output
OUTPUT_DIRECTORY=./output

# ========================================
# Feature Flags
# ========================================

# Enable LLM response caching (future feature) - Default: false
ENABLE_CACHING=false
